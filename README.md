# NLP_Wikipedia_Text_Preprocessing_and_Visualization

Dieses Projekt konzentriert sich auf die Anwendung von natürlicher Sprachverarbeitung (NLP) auf Wikipedia-Textdaten. Ziel ist es, diese Daten vorzubereiten, zu analysieren und visuell darzustellen.

Problembeschreibung:
Es werden Textvorverarbeitungs- und Bereinigungsverfahren auf Wikipedia-Daten angewendet, gefolgt von Visualisierungsarbeiten.

Datensatzgeschichte:
Die Daten stammen direkt aus Wikipedia-Artikeln und werden für die Analyse verwendet.

Verwendete Werkzeuge und Einstellungen:
Das Projekt nutzt Python mit Bibliotheken wie pandas, matplotlib, wordcloud, NLTK (für Stoppwörter) und TextBlob (für Lemmatisierung).

Das Hauptziel ist es, Textdaten so aufzubereiten, dass sie für weiterführende Analysen oder zur Visualisierung optimal nutzbar sind. Verschiedene Aufgaben wie Textbereinigung, Entfernung von Stoppwörtern, Lemmatisierung und die Erstellung von Barplots sowie WordClouds werden im Rahmen dieser Arbeit durchgeführt.
